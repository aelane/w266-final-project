{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import urllib.request\n",
    "import io\n",
    "from nltk import tokenize\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from http://jmcauley.ucsd.edu/data/amazon/links.html\n",
    "\n",
    "R. He, J. McAuley. Modeling the visual evolution of fashion trends with one-class collaborative filtering. WWW, 2016\n",
    "\n",
    "\n",
    "J. McAuley, C. Targett, J. Shi, A. van den Hengel. Image-based recommendations on styles and substitutes. SIGIR, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/amkabatznick/w266-final-project/data/raw/amazon/reviews_Office_Products_5.json.gz'\n",
    "#path = '/home/amkabatznick/w266-final-project/data/raw/amazon/reviews_Musical_Instruments_5.json.gz'\n",
    "path = '/home/amkabatznick/w266-final-project/data/raw/amazon/reviews_Sports_and_Outdoors_5.json.gz'\n",
    "#product = 'Office_Products'\n",
    "product_group = 'Sports_Outdoors'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'rb') \n",
    "    for l in g: \n",
    "        yield eval(l) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(path): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in parse(path): \n",
    "        df[i] = d \n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index').rename(columns={'reviewTime': 'reviewDate'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Product Reviews into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIXZKN4ACSKI</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>David Briner</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This came in on time and I am veru happy with ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Woks very good</td>\n",
       "      <td>1390694400</td>\n",
       "      <td>01 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L5P841VIO02V</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jason A. Kramer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I had a factory Glock tool that I was using fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Works as well as the factory tool</td>\n",
       "      <td>1328140800</td>\n",
       "      <td>02 2, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB2W04NI4OEAD</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>J. Fernald</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>If you don't have a 3/32 punch or would like t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a punch, that's all.</td>\n",
       "      <td>1330387200</td>\n",
       "      <td>02 28, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A148SVSWKTJKU6</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jusitn A. Watts \"Maverick9614\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This works no better than any 3/32 punch you w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a punch with a Glock logo.</td>\n",
       "      <td>1328400000</td>\n",
       "      <td>02 5, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWJ6LW9WMOO</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Material Man</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased this thinking maybe I need a speci...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Ok,tool does what a regular punch does.</td>\n",
       "      <td>1366675200</td>\n",
       "      <td>04 23, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0    AIXZKN4ACSKI  1881509818                    David Briner  [0, 0]   \n",
       "1  A1L5P841VIO02V  1881509818                 Jason A. Kramer  [1, 1]   \n",
       "2   AB2W04NI4OEAD  1881509818                      J. Fernald  [2, 2]   \n",
       "3  A148SVSWKTJKU6  1881509818  Jusitn A. Watts \"Maverick9614\"  [0, 0]   \n",
       "4   AAAWJ6LW9WMOO  1881509818                    Material Man  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This came in on time and I am veru happy with ...      5.0   \n",
       "1  I had a factory Glock tool that I was using fo...      5.0   \n",
       "2  If you don't have a 3/32 punch or would like t...      4.0   \n",
       "3  This works no better than any 3/32 punch you w...      4.0   \n",
       "4  I purchased this thinking maybe I need a speci...      4.0   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewDate  \n",
       "0                           Woks very good      1390694400  01 26, 2014  \n",
       "1        Works as well as the factory tool      1328140800   02 2, 2012  \n",
       "2                It's a punch, that's all.      1330387200  02 28, 2012  \n",
       "3          It's a punch with a Glock logo.      1328400000   02 5, 2012  \n",
       "4  Ok,tool does what a regular punch does.      1366675200  04 23, 2013  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_group = getDF(path)\n",
    "df_product_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper functions to find all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nouns(sentences):\n",
    "    \"For a given sentence it finds the first Noun and classifies that as a feature\"\n",
    "    \n",
    "    features = pd.DataFrame(columns=['features','sentences'])\n",
    "    #nouns = ['NN','NNS','NNP','\tNNPS']\n",
    "    nouns = ['NN','NNS']\n",
    "    #loops through all sentences\n",
    "    for i in range(len(sentences)):\n",
    "        #tags each word in a sentence with a Part of Speech\n",
    "        tags = nltk.pos_tag(nltk.word_tokenize(sentences[i]))\n",
    "        #For each word/tag paring\n",
    "        for word in tags:\n",
    "            if word[1] in nouns:\n",
    "                #Find the first noun tag and call this our feature\n",
    "                features = features.append(pd.DataFrame(data=[[word[0],sentences[i]]],columns=['features','sentences']),ignore_index=True)\n",
    "                break\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_product_features(product_dataframe):\n",
    "    \"\"\"\n",
    "        Used to extract all features for a given product and consildate them under one dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #Used to Time the function\n",
    "    start = time.time()\n",
    "    last = start\n",
    "    #What the output array will look like\n",
    "    columns=['features','sentences','product_id','review_helpful']\n",
    "    all_product_features = pd.DataFrame(columns=columns)\n",
    "    total_reviews = len(product_dataframe)\n",
    "    #loop through all reviews for this product\n",
    "    for i in product_dataframe.index:\n",
    "        #Prints time for larger datasets\n",
    "        if total_reviews>1000 and i % 1000==0:\n",
    "            print('Currently Parsing Review {:,}'.format(i))\n",
    "            end = time.time()\n",
    "            hours, rem = divmod(end-start, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            print(\"The total code has been running for: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "            \n",
    "            hours, rem = divmod(end-last, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            print(\"The last 1,000 took: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "            last = end\n",
    "        \n",
    "        #Splits each review into Sentence\n",
    "        sentence = tokenize.sent_tokenize(product_dataframe.reviewText[i])\n",
    "        #Finds the feature (Noun) of each sentence\n",
    "        product_features = find_nouns(sentence)\n",
    "        #Adds the product_ID and the helpfulness score\n",
    "        product_features['product_id'] = product_dataframe.asin[i]\n",
    "        product_features['review_helpful'] = product_dataframe.helpful[i][0]\n",
    "        \n",
    "        #Adds to Data\n",
    "        all_product_features = all_product_features.append(product_features,ignore_index=True)\n",
    "    \n",
    "    return all_product_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_product_features_over_10(product_id,product_features):\n",
    "        '''Used to filter down the product/feature pairing that has at least 10 reviews'''\n",
    "        #For a given product dataframe find the number of features\n",
    "        grouped_product_features_10 = product_features.groupby(['features'])\n",
    "        #Keep only those features with a count greater than 10\n",
    "        distinct_grouped_product_features_10 = grouped_product_features_10.filter(lambda x: x.count()['review_helpful'] > 10)\n",
    "        return distinct_grouped_product_features_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_text(product_id,distinct_grouped_product_features_10):\n",
    "    '''Generates a text file for each product/feature pairing'''\n",
    "    #Find the distinct features\n",
    "    distinct_features = distinct_grouped_product_features_10.groupby(['features']\n",
    "                                                 )['review_helpful'].size().reset_index()[['features']]\n",
    "    \n",
    "    #Loop through each distinct feature\n",
    "    for i in distinct_features.index:\n",
    "        feature = distinct_features['features'].loc[i]\n",
    "        text_file_path = \"/home/amkabatznick/w266-final-project/data/processed/amazon/{0:}/{1:}_{2:}.txt\".format(product_group,product_id,feature)\n",
    "        text_file_path_exists = os.path.isfile(text_file_path)\n",
    "        #See if the file already exists. If it does continue, else write the file.\n",
    "        if not text_file_path_exists:\n",
    "            #Find the sentences related to this feature\n",
    "            all_sentences = distinct_grouped_product_features_10[(distinct_grouped_product_features_10.features==feature)]\n",
    "            \n",
    "            #Take the 3 most helpful reviews and uses those as a our summary. \n",
    "            #If ties or no feature review was rated helpful then you just pick the last 3 reviews from the sort\n",
    "            MaxSentences = all_sentences.sort_values('review_helpful')[-3:]['sentences'].values\n",
    "            \n",
    "            #Join the first 100 sentences or less (including the most helpful) as our sentences\n",
    "            text_of_review = ' '.join(all_sentences.sentences[:100].values)\n",
    "            #Join the body of the text with oue most helpful summary\n",
    "            text_of_review = text_of_review+'\\n\\n@highlight\\n\\n'.join(np.insert(MaxSentences,0,''))\n",
    "            \n",
    "            #Write the text to file\n",
    "            with open(text_file_path, \"w\") as text_file:\n",
    "                text_file.write(text_of_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_products():\n",
    "    #Used to Time the function\n",
    "    start = time.time()\n",
    "    last = start\n",
    "    \n",
    "    '''Does all product/feature parsing for all reviews and writes these to file'''\n",
    "    #Find all distinct products\n",
    "    products = df_product_group.asin.unique()\n",
    "    \n",
    "    #Find how many products equate to 1 Perecent of the data\n",
    "    one_percent = round(len(products)/100)\n",
    "\n",
    "    for i,product in enumerate(products):\n",
    "        #Used to track what percentage of the data we are through and show how long things are taking\n",
    "        if i % one_percent == 0:\n",
    "            print('Processed {}% of the Data'.format(i/one_percent))\n",
    "            end = time.time()\n",
    "            hours, rem = divmod(end-start, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            print(\"The total code has been running for: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "            \n",
    "            hours, rem = divmod(end-last, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            print(\"The last 1 percent took: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "            last = end\n",
    "            \n",
    "        #Check if a given product dataset already exists\n",
    "        csv_path = '/home/amkabatznick/w266-final-project/data/processed/amazon/{}/{}_reviews_data.csv'.format(product_group,product)\n",
    "        csv_exists = os.path.isfile(csv_path)\n",
    "        if csv_exists:\n",
    "            #If it exists then see if we need to generate the text files\n",
    "            all_product_features = pd.read_csv(csv_path)\n",
    "            generate_feature_text(product,all_product_features)\n",
    "        else:\n",
    "            #If the file does not exist for the product then generate the product/feature file\n",
    "            df_product = df_product_group[df_product_group.asin == product]\n",
    "            if len(df_product) >1000:\n",
    "                print('This product has {} reviews'.format(len(df_product)))\n",
    "\n",
    "            product_features = find_all_product_features(df_product)\n",
    "            \n",
    "            if not product_features.empty:\n",
    "                #If product features exists, see if there is a product/feature pairing of at least 10\n",
    "                all_product_features = find_product_features_over_10(product,product_features)\n",
    "\n",
    "                if not all_product_features.empty:\n",
    "                    #If the produt/feature pairing of at least 10 exists then write it to CSV and generate the text files\n",
    "                    all_product_features.to_csv(csv_path)\n",
    "                    generate_feature_text(product,all_product_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0.0% of the Data\n",
      "The total code has been running for: 00:00:00.03\n",
      "The last 1 perecent took: 00:00:00.03\n",
      "Processed 1.0% of the Data\n",
      "The total code has been running for: 00:01:00.43\n",
      "The last 1 perecent took: 00:01:00.39\n",
      "Processed 2.0% of the Data\n",
      "The total code has been running for: 00:02:02.69\n",
      "The last 1 perecent took: 00:01:02.26\n",
      "Processed 3.0% of the Data\n",
      "The total code has been running for: 00:03:03.63\n",
      "The last 1 perecent took: 00:01:00.94\n",
      "Processed 4.0% of the Data\n",
      "The total code has been running for: 00:04:06.19\n",
      "The last 1 perecent took: 00:01:02.56\n",
      "Processed 5.0% of the Data\n",
      "The total code has been running for: 00:05:05.89\n",
      "The last 1 perecent took: 00:00:59.71\n",
      "Processed 6.0% of the Data\n",
      "The total code has been running for: 00:06:01.43\n",
      "The last 1 perecent took: 00:00:55.54\n",
      "Processed 7.0% of the Data\n",
      "The total code has been running for: 00:07:12.01\n",
      "The last 1 perecent took: 00:01:10.57\n",
      "Processed 8.0% of the Data\n",
      "The total code has been running for: 00:08:12.86\n",
      "The last 1 perecent took: 00:01:00.85\n",
      "Processed 9.0% of the Data\n",
      "The total code has been running for: 00:09:10.43\n",
      "The last 1 perecent took: 00:00:57.58\n",
      "Processed 10.0% of the Data\n",
      "The total code has been running for: 00:10:24.66\n",
      "The last 1 perecent took: 00:01:14.22\n",
      "Processed 11.0% of the Data\n",
      "The total code has been running for: 00:11:25.08\n",
      "The last 1 perecent took: 00:01:00.42\n",
      "Processed 12.0% of the Data\n",
      "The total code has been running for: 00:12:28.63\n",
      "The last 1 perecent took: 00:01:03.55\n",
      "Processed 13.0% of the Data\n",
      "The total code has been running for: 00:13:44.31\n",
      "The last 1 perecent took: 00:01:15.68\n",
      "Processed 14.0% of the Data\n",
      "The total code has been running for: 00:14:46.93\n",
      "The last 1 perecent took: 00:01:02.63\n",
      "Processed 15.0% of the Data\n",
      "The total code has been running for: 00:15:54.98\n",
      "The last 1 perecent took: 00:01:08.05\n",
      "Processed 16.0% of the Data\n",
      "The total code has been running for: 00:17:05.37\n",
      "The last 1 perecent took: 00:01:10.39\n",
      "Processed 17.0% of the Data\n",
      "The total code has been running for: 00:18:02.26\n",
      "The last 1 perecent took: 00:00:56.90\n",
      "Processed 18.0% of the Data\n",
      "The total code has been running for: 00:18:51.44\n",
      "The last 1 perecent took: 00:00:49.17\n",
      "Processed 19.0% of the Data\n",
      "The total code has been running for: 00:19:47.03\n",
      "The last 1 perecent took: 00:00:55.59\n",
      "Processed 20.0% of the Data\n",
      "The total code has been running for: 00:20:48.71\n",
      "The last 1 perecent took: 00:01:01.67\n",
      "Processed 21.0% of the Data\n",
      "The total code has been running for: 00:21:40.64\n",
      "The last 1 perecent took: 00:00:51.93\n",
      "Processed 22.0% of the Data\n",
      "The total code has been running for: 00:22:39.49\n",
      "The last 1 perecent took: 00:00:58.85\n",
      "Processed 23.0% of the Data\n",
      "The total code has been running for: 00:23:51.14\n",
      "The last 1 perecent took: 00:01:11.64\n",
      "Processed 24.0% of the Data\n",
      "The total code has been running for: 00:24:50.95\n",
      "The last 1 perecent took: 00:00:59.81\n",
      "Processed 25.0% of the Data\n",
      "The total code has been running for: 00:25:50.61\n",
      "The last 1 perecent took: 00:00:59.66\n",
      "Processed 26.0% of the Data\n",
      "The total code has been running for: 00:26:44.95\n",
      "The last 1 perecent took: 00:00:54.34\n",
      "Processed 27.0% of the Data\n",
      "The total code has been running for: 00:27:43.19\n",
      "The last 1 perecent took: 00:00:58.23\n",
      "Processed 28.0% of the Data\n",
      "The total code has been running for: 00:28:43.91\n",
      "The last 1 perecent took: 00:01:00.72\n",
      "Processed 29.0% of the Data\n",
      "The total code has been running for: 00:29:56.08\n",
      "The last 1 perecent took: 00:01:12.17\n",
      "Processed 30.0% of the Data\n",
      "The total code has been running for: 00:31:01.02\n",
      "The last 1 perecent took: 00:01:04.94\n",
      "Processed 31.0% of the Data\n",
      "The total code has been running for: 00:32:03.56\n",
      "The last 1 perecent took: 00:01:02.54\n",
      "Processed 32.0% of the Data\n",
      "The total code has been running for: 00:33:12.35\n",
      "The last 1 perecent took: 00:01:08.79\n",
      "Processed 33.0% of the Data\n",
      "The total code has been running for: 00:34:18.91\n",
      "The last 1 perecent took: 00:01:06.56\n",
      "Processed 34.0% of the Data\n",
      "The total code has been running for: 00:35:49.18\n",
      "The last 1 perecent took: 00:01:30.27\n",
      "Processed 35.0% of the Data\n",
      "The total code has been running for: 00:36:52.89\n",
      "The last 1 perecent took: 00:01:03.71\n",
      "Processed 36.0% of the Data\n",
      "The total code has been running for: 00:37:56.75\n",
      "The last 1 perecent took: 00:01:03.86\n",
      "Processed 37.0% of the Data\n",
      "The total code has been running for: 00:39:01.90\n",
      "The last 1 perecent took: 00:01:05.15\n",
      "Processed 38.0% of the Data\n",
      "The total code has been running for: 00:39:50.87\n",
      "The last 1 perecent took: 00:00:48.98\n",
      "This product has 1042 reviews\n",
      "Currently Parsing Review 125,000\n",
      "The total code has been running for: 00:00:05.07\n",
      "The last 1,000 took: 00:00:05.07\n",
      "Processed 39.0% of the Data\n",
      "The total code has been running for: 00:41:17.19\n",
      "The last 1 perecent took: 00:01:26.32\n",
      "Processed 40.0% of the Data\n",
      "The total code has been running for: 00:42:22.05\n",
      "The last 1 perecent took: 00:01:04.86\n",
      "Processed 41.0% of the Data\n",
      "The total code has been running for: 00:43:21.70\n",
      "The last 1 perecent took: 00:00:59.65\n",
      "Processed 44.0% of the Data\n",
      "The total code has been running for: 00:46:27.82\n",
      "The last 1 perecent took: 00:01:16.85\n",
      "Processed 45.0% of the Data\n",
      "The total code has been running for: 00:47:48.42\n",
      "The last 1 perecent took: 00:01:20.61\n",
      "Processed 46.0% of the Data\n",
      "The total code has been running for: 00:48:49.01\n",
      "The last 1 perecent took: 00:01:00.59\n",
      "Processed 47.0% of the Data\n",
      "The total code has been running for: 00:49:49.64\n",
      "The last 1 perecent took: 00:01:00.63\n",
      "Processed 48.0% of the Data\n",
      "The total code has been running for: 00:50:55.84\n",
      "The last 1 perecent took: 00:01:06.20\n",
      "Processed 49.0% of the Data\n",
      "The total code has been running for: 00:51:53.08\n",
      "The last 1 perecent took: 00:00:57.24\n",
      "Processed 50.0% of the Data\n",
      "The total code has been running for: 00:52:53.21\n",
      "The last 1 perecent took: 00:01:00.13\n",
      "Processed 51.0% of the Data\n",
      "The total code has been running for: 00:53:59.15\n",
      "The last 1 perecent took: 00:01:05.94\n",
      "Processed 52.0% of the Data\n",
      "The total code has been running for: 00:55:08.66\n",
      "The last 1 perecent took: 00:01:09.52\n",
      "Processed 53.0% of the Data\n",
      "The total code has been running for: 00:56:18.52\n",
      "The last 1 perecent took: 00:01:09.86\n",
      "Processed 54.0% of the Data\n",
      "The total code has been running for: 00:57:30.92\n",
      "The last 1 perecent took: 00:01:12.40\n",
      "Processed 55.0% of the Data\n",
      "The total code has been running for: 00:58:49.67\n",
      "The last 1 perecent took: 00:01:18.75\n",
      "Processed 56.0% of the Data\n",
      "The total code has been running for: 00:59:53.53\n",
      "The last 1 perecent took: 00:01:03.86\n",
      "Processed 57.0% of the Data\n",
      "The total code has been running for: 01:00:51.90\n",
      "The last 1 perecent took: 00:00:58.37\n",
      "Processed 58.0% of the Data\n",
      "The total code has been running for: 01:01:43.66\n",
      "The last 1 perecent took: 00:00:51.76\n",
      "Processed 59.0% of the Data\n",
      "The total code has been running for: 01:02:48.30\n",
      "The last 1 perecent took: 00:01:04.64\n",
      "Processed 60.0% of the Data\n",
      "The total code has been running for: 01:03:51.01\n",
      "The last 1 perecent took: 00:01:02.71\n",
      "Processed 61.0% of the Data\n",
      "The total code has been running for: 01:04:53.46\n",
      "The last 1 perecent took: 00:01:02.44\n",
      "Processed 62.0% of the Data\n",
      "The total code has been running for: 01:05:44.25\n",
      "The last 1 perecent took: 00:00:50.79\n",
      "Processed 63.0% of the Data\n",
      "The total code has been running for: 01:06:34.68\n",
      "The last 1 perecent took: 00:00:50.44\n",
      "Processed 64.0% of the Data\n",
      "The total code has been running for: 01:07:39.35\n",
      "The last 1 perecent took: 00:01:04.67\n",
      "Processed 65.0% of the Data\n",
      "The total code has been running for: 01:08:35.90\n",
      "The last 1 perecent took: 00:00:56.54\n",
      "Processed 66.0% of the Data\n",
      "The total code has been running for: 01:09:36.79\n",
      "The last 1 perecent took: 00:01:00.89\n",
      "Processed 67.0% of the Data\n",
      "The total code has been running for: 01:10:41.84\n",
      "The last 1 perecent took: 00:01:05.05\n",
      "Processed 68.0% of the Data\n",
      "The total code has been running for: 01:11:44.58\n",
      "The last 1 perecent took: 00:01:02.74\n",
      "Processed 69.0% of the Data\n",
      "The total code has been running for: 01:12:50.50\n",
      "The last 1 perecent took: 00:01:05.91\n",
      "Processed 70.0% of the Data\n",
      "The total code has been running for: 01:13:45.69\n",
      "The last 1 perecent took: 00:00:55.20\n",
      "Processed 71.0% of the Data\n",
      "The total code has been running for: 01:14:49.88\n",
      "The last 1 perecent took: 00:01:04.19\n",
      "Processed 72.0% of the Data\n",
      "The total code has been running for: 01:15:50.33\n",
      "The last 1 perecent took: 00:01:00.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 73.0% of the Data\n",
      "The total code has been running for: 01:16:47.25\n",
      "The last 1 perecent took: 00:00:56.92\n",
      "Processed 74.0% of the Data\n",
      "The total code has been running for: 01:18:00.53\n",
      "The last 1 perecent took: 00:01:13.28\n",
      "Processed 75.0% of the Data\n",
      "The total code has been running for: 01:18:51.08\n",
      "The last 1 perecent took: 00:00:50.55\n",
      "Processed 76.0% of the Data\n",
      "The total code has been running for: 01:19:46.95\n",
      "The last 1 perecent took: 00:00:55.87\n",
      "Processed 77.0% of the Data\n",
      "The total code has been running for: 01:20:34.08\n",
      "The last 1 perecent took: 00:00:47.13\n",
      "Processed 78.0% of the Data\n",
      "The total code has been running for: 01:21:27.64\n",
      "The last 1 perecent took: 00:00:53.56\n",
      "Processed 79.0% of the Data\n",
      "The total code has been running for: 01:22:31.31\n",
      "The last 1 perecent took: 00:01:03.67\n",
      "Processed 80.0% of the Data\n",
      "The total code has been running for: 01:23:17.92\n",
      "The last 1 perecent took: 00:00:46.61\n",
      "Processed 81.0% of the Data\n",
      "The total code has been running for: 01:24:08.27\n",
      "The last 1 perecent took: 00:00:50.35\n",
      "Processed 82.0% of the Data\n",
      "The total code has been running for: 01:25:15.39\n",
      "The last 1 perecent took: 00:01:07.12\n",
      "Processed 83.0% of the Data\n",
      "The total code has been running for: 01:26:06.65\n",
      "The last 1 perecent took: 00:00:51.26\n",
      "Processed 84.0% of the Data\n",
      "The total code has been running for: 01:27:00.71\n",
      "The last 1 perecent took: 00:00:54.07\n",
      "Processed 85.0% of the Data\n",
      "The total code has been running for: 01:27:48.31\n",
      "The last 1 perecent took: 00:00:47.60\n",
      "Processed 86.0% of the Data\n",
      "The total code has been running for: 01:28:42.18\n",
      "The last 1 perecent took: 00:00:53.87\n",
      "Processed 87.0% of the Data\n",
      "The total code has been running for: 01:29:29.42\n",
      "The last 1 perecent took: 00:00:47.23\n",
      "Processed 88.0% of the Data\n",
      "The total code has been running for: 01:30:24.46\n",
      "The last 1 perecent took: 00:00:55.04\n",
      "Processed 89.0% of the Data\n",
      "The total code has been running for: 01:31:11.42\n",
      "The last 1 perecent took: 00:00:46.96\n",
      "Processed 90.0% of the Data\n",
      "The total code has been running for: 01:32:08.06\n",
      "The last 1 perecent took: 00:00:56.64\n",
      "Processed 91.0% of the Data\n",
      "The total code has been running for: 01:32:57.10\n",
      "The last 1 perecent took: 00:00:49.04\n",
      "Processed 92.0% of the Data\n",
      "The total code has been running for: 01:33:46.95\n",
      "The last 1 perecent took: 00:00:49.85\n",
      "Processed 93.0% of the Data\n",
      "The total code has been running for: 01:34:35.17\n",
      "The last 1 perecent took: 00:00:48.22\n",
      "Processed 94.0% of the Data\n",
      "The total code has been running for: 01:35:24.13\n",
      "The last 1 perecent took: 00:00:48.96\n",
      "Processed 95.0% of the Data\n",
      "The total code has been running for: 01:36:17.76\n",
      "The last 1 perecent took: 00:00:53.63\n",
      "Processed 96.0% of the Data\n",
      "The total code has been running for: 01:37:16.82\n",
      "The last 1 perecent took: 00:00:59.06\n",
      "Processed 97.0% of the Data\n",
      "The total code has been running for: 01:38:10.61\n",
      "The last 1 perecent took: 00:00:53.79\n",
      "Processed 98.0% of the Data\n",
      "The total code has been running for: 01:39:03.91\n",
      "The last 1 perecent took: 00:00:53.30\n",
      "Processed 99.0% of the Data\n",
      "The total code has been running for: 01:40:09.98\n",
      "The last 1 perecent took: 00:01:06.07\n"
     ]
    }
   ],
   "source": [
    "parse_all_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    all_features = pd.read_csv('/home/amkabatznick/w266-final-project/data/processed/amazon/{}/reviews_data.csv'.format(product))\n",
    "#except:\n",
    "#    all_features = find_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_features_10 = all_features.groupby(['features','product_id'])\n",
    "#distinct_grouped_features_10 = grouped_features_10.filter(lambda x: x.count()['review_helpful'] > 10)\n",
    "\n",
    "#distinct_grouped_features_10.to_csv('/home/amkabatznick/w266-final-project/data/processed/amazon/{}/reviews_data.csv'.format(product))\n",
    "\n",
    "\n",
    "#distinct_grouped_features_10.groupby(['features','product_id'])['review_helpful'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distinct_grouped_features_10.groupby(['features','product_id'])['review_helpful'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distinct_features = distinct_grouped_features_10.groupby(['features','product_id']\n",
    "#                                                        )['review_helpful'].size().reset_index()[['features',\n",
    "#                                                                                                  'product_id']]\n",
    "\n",
    "#for i in distinct_features.index:\n",
    "    #features = distinct_features['features'].loc[i]\n",
    "    \n",
    "    #product_id = distinct_features['product_id'].loc[i]\n",
    "    \n",
    "    #all_sentences = distinct_grouped_features_10[(distinct_grouped_features_10.product_id==product_id) & \n",
    "    #                    (distinct_grouped_features_10.features==features)]\n",
    "\n",
    "    #MaxSentences = ['']\n",
    "    #for i in range(3):\n",
    "        #current_max = all_sentences.review_helpful.astype(float).idxmax(axis=0)\n",
    "        #MaxSentences.append(all_sentences.loc[current_max]['sentences'])\n",
    "        #all_sentences.drop(current_max,inplace=True)\n",
    "\n",
    "    #MaxSentences = all_sentences.sort_values('review_helpful')[-3:]['sentences'].values\n",
    "    \n",
    "    #text_of_review = ' '.join(all_sentences.sentences[:100].values)\n",
    "    #text_of_review = text_of_review+'\\n\\n@highlight\\n\\n'.join(np.insert(MaxSentences,0,''))\n",
    "    #with open(\"/home/amkabatznick/w266-final-project/data/processed/amazon/{0:}/{1:}_{2:}.txt\".format(product,product_id,features), \"w\") as text_file:\n",
    "    #    text_file.write(text_of_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
